{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 29 tokens\n",
      "\n",
      "{'Gensim': 0, 'Python': 1, 'a': 2, 'algorithms.': 3, 'and': 4, 'as': 5, 'designed': 6, 'digital': 7, 'documents': 8, 'efficiently': 9, 'for': 10, 'free': 11, 'is': 12, 'learning': 13, 'library': 14, 'machine': 15, 'open-source': 16, 'painlessly': 17, 'possible.': 18, 'process': 19, 'raw,': 20, 'representing': 21, 'semantic': 22, 'texts': 23, 'to': 24, 'unstructured': 25, 'unsupervised': 26, 'using': 27, 'vectors,': 28}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "text1 = [\"\"\"Gensim is a free open-source Python library for representing documents as semantic vectors,\n",
    "           as efficiently and painlessly as possible. Gensim is designed \n",
    "           to process raw, unstructured digital texts using unsupervised machine learning algorithms.\"\"\"]\n",
    "\n",
    "tokens1 = [[item for item in line.split()] for line in text1]\n",
    "g_dict1 = corpora.Dictionary(tokens1)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict1)) + \" tokens\\n\")\n",
    "print(g_dict1.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words :  [[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
     ]
    }
   ],
   "source": [
    "g_bow =[g_dict1.doc2bow(token, allow_update = True) for token in tokens1]\n",
    "print(\"Bag of Words : \", g_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary : \n",
      "[['be', 1], ['better', 1], ['but', 1], ['can', 1], ['excellent', 1], ['food', 1], ['is', 1], ['service', 1], ['the', 2]]\n",
      "[['food', 1], ['is', 1], ['service', 1], ['the', 2], ['always', 1], ['and', 1], ['delicious', 1], ['loved', 1]]\n",
      "[['food', 1], ['service', 1], ['the', 2], ['and', 1], ['mediocre', 1], ['terrible', 1], ['was', 2]]\n",
      "TF-IDF Vector:\n",
      "[['be', 0.43], ['better', 0.43], ['but', 0.43], ['can', 0.43], ['excellent', 0.43], ['food', 0.09], ['is', 0.21], ['service', 0.09], ['the', 0.18]]\n",
      "[['food', 0.11], ['is', 0.26], ['service', 0.11], ['the', 0.21], ['always', 0.52], ['and', 0.26], ['delicious', 0.52], ['loved', 0.52]]\n",
      "[['food', 0.08], ['service', 0.08], ['the', 0.16], ['and', 0.2], ['mediocre', 0.39], ['terrible', 0.39], ['was', 0.78]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "\n",
    "# Sample text\n",
    "text = [\"The food is excellent but the service can be better\",\n",
    "        \"The food is always delicious and loved the service\",\n",
    "        \"The food was mediocre and the service was terrible\"]\n",
    "\n",
    "# Create a dictionary and a bag-of-words (BoW) corpus\n",
    "g_dict = corpora.Dictionary([simple_preprocess(line) for line in text])\n",
    "g_bow = [g_dict.doc2bow(simple_preprocess(line)) for line in text]\n",
    "\n",
    "# Print the BoW representation\n",
    "print(\"Dictionary : \")\n",
    "for item in g_bow:\n",
    "    print([[g_dict[id], freq] for id, freq in item])\n",
    "\n",
    "# Create a TF-IDF model\n",
    "g_tfidf = models.TfidfModel(g_bow, smartirs='ntc')\n",
    "\n",
    "# Print the TF-IDF representation\n",
    "print(\"TF-IDF Vector:\")\n",
    "for item in g_tfidf[g_bow]:\n",
    "    print([[g_dict[id], np.around(freq, decimals=2)] for id, freq in item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "import gensim.downloader as api\n",
    "\n",
    "dataset = api.load(\"text8\")\n",
    "words = [d for d in dataset]\n",
    "\n",
    "data1 = words[:1000]\n",
    "w2v_model = Word2Vec(data1, min_count = 0, workers=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word vector for 'service':\n",
      " [ 2.6918826  -0.426363    3.4098058  -2.225435    0.01576584 -1.657481\n",
      " -0.25096825 -1.2883489   1.7208221   0.4164066   1.8191155  -1.9158213\n",
      "  1.5740644   0.8696585   0.45638767 -0.60900885  0.6489568   1.072156\n",
      "  0.4573284  -1.9745895   0.7708862  -0.05540381 -0.9771591   0.23771837\n",
      " -0.14038394  1.6806232   1.5502543   0.45755035 -0.4022828   1.7237673\n",
      " -0.6433264   0.84633946 -2.8816407  -0.3603856  -1.5032923  -2.4225917\n",
      "  1.4155889  -2.4237328  -0.3548736   0.5125505  -3.4372883   0.28157535\n",
      " -2.0293      1.643747   -2.551914   -1.3040798  -0.21132892  1.2344356\n",
      "  1.4983875   2.723901   -1.5391455  -1.5445918   1.0350138   0.5357209\n",
      " -0.39968297 -1.0089308   1.9309181   1.7833318  -2.2138474   0.43255952\n",
      "  0.27062684 -0.45434377  0.53598696  0.7331825  -0.43786472  0.23419012\n",
      " -1.487662    0.5992024  -2.1934562   0.49401972  2.0896049   2.1591113\n",
      "  0.19851218  1.8651133   0.6176218   1.2261645   0.9219802  -0.71965295\n",
      "  0.4876182   0.7274301   0.05149831  0.6287987  -0.779014    0.22759357\n",
      "  0.34987843 -0.93217784  0.47594562 -0.23519374  1.4888738   1.2340477\n",
      "  1.048806    0.67708325  0.13510345 -1.3530886  -1.6788015   4.2925205\n",
      "  1.779704    0.00785432 -0.17397688  2.1074438 ]\n"
     ]
    }
   ],
   "source": [
    "word = 'service'\n",
    "if word in w2v_model.wv:\n",
    "    print(f\"\\nWord vector for '{word}':\\n\", w2v_model.wv[word])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
